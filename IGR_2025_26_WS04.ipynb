{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0h1/4OMPQtjkgF7GIVJOm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laura-turnbull-lloyd/IGR_remote_sensing/blob/main/IGR_2025_26_WS04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IGR Workshop 4: Using remote sensing to detect surface changes over time\n",
        "_Laura Turnbull-Lloyd, IGR, 2026._\n",
        "\n",
        "# Overview\n",
        "In the session last week, you explored the structure of a Landsat image, had a go at visualizing different band combinations, and then you calculated 3 indices:\n",
        "*  Normalized Difference Vegetation Index (NDVI)\n",
        "*  Enhanced Vegetation Index (EVI)\n",
        "*  Normalized Difference Moisture Index (NDMI)\n",
        "\n",
        "You then undertook some preliminary analysis to see how these indices varied for different surface cover types that you mapped out in the field.\n",
        "\n",
        "This week, we are going to build on the work you undertook last week, to use a time sequence of Landsat images to explore changes in surface characteristics over both space and time, really delving into the power that remote sensing offers.\n",
        "\n",
        "This week we will build directly on that foundation by adding a temporal dimension. Using a time sequence of Landsat images, you will explore how surface characteristics change throughout the year and across the Langdon Beck catchment, and you will see how the conclusions you draw depend on data quality, especially cloud and shadow contamination.\n",
        "\n",
        "By the end of the worksheet you should be able to:\n",
        "\n",
        "* create and interpret a monthly EVI time series\n",
        "* link patterns in EVI to what you observed in the field (e.g., vegetation condition, land cover, seasonality)\n",
        "* recognise when apparent \"change\" is actually an artefact of clouds, snow, or limited observations, and understand why it is important to pay attention to data quality indicators\n"
      ],
      "metadata": {
        "id": "Hcms4rJny4Lo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data you will work with\n",
        "Last week you worked with Landsat Level 2 surface reflectance data, and from this you calculated the Enhanced Vegetation Index, which is generally considered to be better for assessing vegetation health than the Normalised Difference Vegetation Index, [Heute et al, 2002](https://doi.org/10.1016/S0034-4257(02)00096-2)).\n",
        "\n",
        "This week, we will focus on temporal variations in the EVI. You already know how to calculate the EVI from Landsat Surface Reflectance products using the following equation.\n",
        "$$\n",
        "\\mathrm{EVI} = G \\, \\frac{\\mathrm{NIR} - \\mathrm{Red}}{\\mathrm{NIR} + C_1\\times\\mathrm{Red} - C_2\\times\\mathrm{Blue} + L}\n",
        "$$\n",
        "\n",
        "This week, to simplify things, you have been provided with the EVI already calculated for you, for nine mostly cloud free images during 2025.\n",
        "\n",
        "The EVI was calculated for you on a platform called [Google Earth Engine](https://earthengine.google.com/) (you don't need to worry about this for now, but if you're interested in exploring remote sensing further, you might like to take a look!).\n",
        "\n",
        "If you recall that the Landsat repeat cycle is 16 days, you might be wondering why there are only nine images for you to work with. The answer is mostly clouds!\n",
        "\n",
        "As noted by [NASA](https://science.nasa.gov/earth/earth-observatory/measuring-vegetation-ndvi-evi/), clouds and aerosols can often block the satellites view of the surface entirely, glare from the sun can saturate certain pixels, and temporary malfunctions in the satellite instruments themselves can distort an image. Consequently, many of the pixels in a day's worth of images are indecipherable, and maps made from the daily Vegetation Indices are patchy at best.\n",
        "\n",
        "One simple approach is to filter the image collection using cloud-cover information, keeping only scenes with relatively clear conditions. In 2025 we have ended up with only 9 images, because only 9 scenes had less than 20% cloud cover within the window that covers Langdon Beck.\n",
        "\n",
        "These images are provided for you as GeoTIFFS (rasters) - one file for each time stamp. The image acquisition date is recorded in the file name. You are also provided with the cloud cover infromation (processed into a simple cloud mask), also provided by Landsat, to enable you to see clearly where the cloud cover occurs for the slightly cloudier images.\n",
        "\n",
        "With these data, you can explore changes in vegetation condition (linked to vegetation phenology) over time within Langdon Beck. The diagram below summarised how we can take the remote sensing EVI product, and from it be able to say something meaningful about changes in vegetation condition over time.\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src='https://github.com/laura-turnbull-lloyd/IGR_remote_sensing/blob/main/Figures/data-to-insight.png?raw=true' width='75%' alt='data-to-insight.png'>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "Mx7nG5162kHt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting started\n",
        "As with last week, we will use the same core packages and functions to download, read in and process the data. These are **matplotlib**, **rasterio** etc.\n",
        "\n",
        "The data are stored for you on a GitHub repository, for easy access, and within this worksheet you will download the data to your google drive, and then work with it from there.\n",
        "\n"
      ],
      "metadata": {
        "id": "08zaDZSS3eoU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions!\n",
        "There are questions throughout the worksheet. You can answer these questions on the microsoft form. This is just for you to check your progress (I won't be looking at any marks). The key thing is that you compare your answer to the suggested answer (don't worry if it says you're wrong if you've given the right answer - it might just be a formatting issue).\n",
        "\n",
        "The link to the questions is [here](https://forms.office.com/e/405JVzXhzL)."
      ],
      "metadata": {
        "id": "dNj1mX7WNyGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title First, you need to run this block to install packages and load libraries.\n",
        "\n",
        "!pip -q install \"geopandas>=0.14\"            # First we install the geopandas package as it isn't a default package in colab\n",
        "import geopandas as gpd                      # Then we load the package - needed for working with the catchment shapefile\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "import os\n",
        "import re\n",
        "import pandas as pd                          # the main packges for working with data\n",
        "import numpy as np\n",
        "import math\n",
        "import rasterio                              # rasterio is the main package we're using for working with the raster data\n",
        "from rasterio.features import geometry_mask\n",
        "from rasterio.windows import from_bounds\n",
        "from rasterio.windows import Window\n",
        "from rasterio.windows import bounds as window_bounds\n",
        "from rasterio.mask import mask\n",
        "from rasterio.features import rasterize\n",
        "from rasterio.features import geometry_mask\n",
        "import glob\n",
        "import zipfile                               # this and the other libraries below are used to import the data from github via a web link (url)\n",
        "from urllib.parse import urlparse\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import requests, io"
      ],
      "metadata": {
        "id": "rpZD0t46MmyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question: What is the main package we'll be using to process the raster data?"
      ],
      "metadata": {
        "id": "Y5G2PqMjNefz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, you can download the data (in a zipped up folder) and then extract the files to your google drive. Don't worry about the detail here - this is just getting the files set up for you."
      ],
      "metadata": {
        "id": "KGuH_g3iE4fq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wklck-BOlB_B"
      },
      "outputs": [],
      "source": [
        "#@title Run this block to download the ZIP and extract all files into a folder\n",
        "\n",
        "# USER SETTINGS\n",
        "ZIP_URL = \"https://github.com/laura-turnbull-lloyd/IGR_remote_sensing/raw/refs/heads/main/Data/L8_EVI_cloudfiltered-20260210T171611Z-1-001.zip\"\n",
        "\n",
        "DOWNLOAD_DIR = \"/content/downloads\"                 # zip file saved here\n",
        "OUT_DIR      = \"/content/L9_EVI_cloudfiltered_files\" # ALL extracted files go here (single folder)\n",
        "\n",
        "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# FUNCTION TO DOWNLOAD THE DATA\n",
        "def download_file(url, filename):\n",
        "    r = requests.get(url, stream=True, allow_redirects=True)\n",
        "    r.raise_for_status()\n",
        "    total = int(r.headers.get(\"content-length\", 0)) or None\n",
        "    chunk = 1024 * 1024  # 1 MB\n",
        "    with open(filename, \"wb\") as f:\n",
        "        with tqdm(total=total, unit=\"B\", unit_scale=True, desc=os.path.basename(filename)) as pbar:\n",
        "            for data in r.iter_content(chunk):\n",
        "                if data:\n",
        "                    f.write(data)\n",
        "                    pbar.update(len(data))\n",
        "\n",
        "# DOWNLOADING THE ZIPPED UP DATA\n",
        "zip_name = os.path.basename(urlparse(ZIP_URL).path)\n",
        "zip_path = os.path.join(DOWNLOAD_DIR, zip_name)\n",
        "\n",
        "print(\"Downloading ZIP...\")\n",
        "download_file(ZIP_URL, zip_path)\n",
        "print(\"ZIP downloaded:\", zip_path)\n",
        "\n",
        "# EXTRACTING THE ZIP CONTENTS INTO OUT_DIR\n",
        "print(\"\\nExtracting files to:\", OUT_DIR)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "    members = [m for m in z.namelist() if not m.endswith(\"/\")]  # files only\n",
        "    for m in tqdm(members, desc=\"Extracting\", unit=\"file\"):\n",
        "        # Force everything into a single folder by stripping subfolders\n",
        "        base = os.path.basename(m)\n",
        "        if base == \"\":\n",
        "            continue\n",
        "\n",
        "        out_path = os.path.join(OUT_DIR, base)\n",
        "\n",
        "        # Extract file bytes and write to OUT_DIR\n",
        "        with z.open(m) as src, open(out_path, \"wb\") as dst:\n",
        "            dst.write(src.read())\n",
        "\n",
        "print(\"\\nDone!\")\n",
        "print(\"Extracted file count:\", len([f for f in os.listdir(OUT_DIR) if os.path.isfile(os.path.join(OUT_DIR, f))]))\n",
        "print(\"First 10 extracted files:\")\n",
        "for f in sorted(os.listdir(OUT_DIR))[:10]:\n",
        "    print(\" -\", f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see in the text above that the files have successfully been downloaded and extracted."
      ],
      "metadata": {
        "id": "mo9lVh1fFTdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting the dates of each image\n",
        "To be able to explore how vegetation condition over time, we need to know the date represented by each image. Conveniently, the data is given in each file name, along with some other useful infromation, e.g.\n",
        "\n",
        "L9_20250309_cloud0pct_EVI.tif.\n",
        "\n",
        "This tells us the Landsat sensor (L9), the date in the format YYYYMMDD, the cloud cover as a %, and what the data are (EVI or cloud mask).\n",
        "\n",
        "So in the above example, it's the EVI calculated for 9th March 2025 and there's 0% cloud cover.\n",
        "\n",
        "## Question: Have a look through the files you've extracted and stored in a folder called \"L9_EVI_cloudfiltered_files\". What's the highest cloud cover in all these files?\n",
        "Tip: to view the files in this folder, click on the folder icon in the left menu bar, and click on the \"L9_EVI....\" folder to view its contents.\n",
        "\n",
        "We can write a code to extract the date from the file name, as well as the type of file (EVI or cloud mask), and ultimately create a list of all the EVI and cloud mask files, along with their corresponding dates.\n",
        "\n",
        "Let's have a go..."
      ],
      "metadata": {
        "id": "VCbtq0HsXgz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Extracting the date of each image and creating lists of EVI and cloud mask files\n",
        "\n",
        "date_re = re.compile(r\"(19|20)\\d{2}(0[1-9]|1[0-2])(0[1-9]|[12]\\d|3[01])\")\n",
        "# Here, re.compile turns the pattern into a reusable “date finder” that we can re-use.\n",
        "# Broken down:\n",
        "# (19|20)\\d{2} matches a 4-digit year from 1900–2099: 19 or 20, followed by two digits (\\d{2})\n",
        "# (0[1-9]|1[0-2]) matches a month 01–12: 01–09 or 10–12\n",
        "# (0[1-9]|[12]\\d|3[01]) matches a day 01–31: 01–09, 10–29, 30–31\n",
        "\n",
        "# Function to identify if the file is an EVI file or a cloud mask file.\n",
        "def classify_file(name: str):\n",
        "    \"\"\"Return 'evi', 'cloudmask', or None based on filename.\"\"\"\n",
        "    base = os.path.basename(name).lower()\n",
        "    if \"cloudmask\" in base or \"cloud_mask\" in base: # this picks out if the file name contains cloud mask\n",
        "        return \"cloudmask\"\n",
        "    if base.endswith(\"_evi.tif\") or \"evi\" in base: # this picks out if the file name contains EVI\n",
        "        return \"evi\"\n",
        "    return None\n",
        "\n",
        "evi_records, cloudmask_records = [], [] # This line creates two empty Python lists in one go where we\n",
        "                                        # will store the dates.\n",
        "\n",
        "# List only the top-level files in OUT_DIR\n",
        "for fn in os.listdir(OUT_DIR):                        # This loop through every file in OUT_DIR\n",
        "    if not fn.lower().endswith((\".tif\", \".tiff\")):    # This ignores any files that aren't tif files\n",
        "        continue\n",
        "\n",
        "    full_path = os.path.join(OUT_DIR, fn)             # This build the full path (the directory and the filename)\n",
        "\n",
        "    date_m = date_re.search(fn)                       # This extracts the date from the filename\n",
        "    date_str = date_m.group(0) if date_m else None    # This extracts a date from the filename and assigns it to date_str\n",
        "    kind = classify_file(fn)                          # This classifies the file as \"evi\" or \"cloudmask\"\n",
        "\n",
        "    rec = {\"path\": full_path, \"filename\": fn, \"date\": date_str, \"kind\": kind} # This creates a \"record\" dictionary storing the useful info about the files.\n",
        "\n",
        "    if kind == \"evi\":                                 # This appends the record to the right list\n",
        "      evi_records.append(rec)\n",
        "    elif kind == \"cloudmask\":\n",
        "      cloudmask_records.append(rec)\n",
        "\n",
        "print(\"EVI files:\", len(evi_records))                 # Finally, this prints out the number of EVI files\n",
        "print(\"Cloudmask files:\", len(cloudmask_records))     # and this prints out the number of cloudmask files.\n",
        "\n",
        "# Sort by date (strings YYYYMMDD sort correctly) (important for later plotting of the time series)\n",
        "evi_records.sort(key=lambda r: (r[\"date\"] is None, r[\"date\"], r[\"filename\"]))\n",
        "cloudmask_records.sort(key=lambda r: (r[\"date\"] is None, r[\"date\"], r[\"filename\"]))\n",
        "\n",
        "print(\"\\nFirst 5 EVI records:\")\n",
        "for r in evi_records[:5]:\n",
        "    print(r[\"date\"], r[\"filename\"])\n"
      ],
      "metadata": {
        "id": "TosnLEnyXNUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question: What's the date of the first EVI file in this data collection for 2025? Give your answer in the format _yyyymmdd_."
      ],
      "metadata": {
        "id": "b7Qyn0B1iFsn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data pre-processing\n",
        "Here, you're going to create a list of dates and file paths (i.e. the location where the file is stored along with the fielname) to read in, in a format that the rasterio package can make sense of, and then extract the spatial information needed for plotting and cropping the data."
      ],
      "metadata": {
        "id": "r1fdMzSCip6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Reading the data into a raster with rasterio\n",
        "\n",
        "# Create a list of dates and paths\n",
        "dates = [r[\"date\"] for r in evi_records]\n",
        "evi_paths = [r[\"path\"] for r in evi_records]\n",
        "cloud_paths = [r[\"path\"] for r in cloudmask_records]\n",
        "\n",
        "# Open the first EVI raster to get bounds/CRS/transform + extent for plotting\n",
        "with rasterio.open(evi_paths[0]) as LB:  # This opens the first file and stores it in \"LB\"\n",
        "    bounds = LB.bounds                   # These are all parameters that make sure the data plots correctly on the right coordinates!\n",
        "    landsat_crs = LB.crs\n",
        "    transform = LB.transform\n",
        "    nodata0 = LB.nodata\n",
        "    height0, width0 = LB.height, LB.width\n",
        "\n",
        "extent = [bounds.left, bounds.right, bounds.bottom, bounds.top]\n",
        "\n",
        "print(\"\\nRaster metadata (from first EVI file):\")       # This just prints out the spatial information below so you can check it\n",
        "print(\" Bounds:\", bounds)\n",
        "print(\" Extent:\", extent)\n",
        "print(\" CRS:\", landsat_crs)\n",
        "print(\" Transform:\", transform)\n",
        "print(\" Shape (height, width):\", (height0, width0))\n",
        "print(\" NoData:\", nodata0)\n",
        "\n",
        "# Read & stack EVI and cloudmask into aligned 3D arrays: (time, y, x)\n",
        "EVI_list = []\n",
        "CLOUD_list = []\n",
        "\n",
        "# This block opens all the data and creates raster stacks for the EVI cloud data and the cloud data.\n",
        "for evi_p, cloud_p in zip(evi_paths, cloud_paths):\n",
        "    # --- Read EVI ---\n",
        "    with rasterio.open(evi_p) as src:\n",
        "        evi_arr = src.read(1).astype(\"float32\")\n",
        "        if src.nodata is not None:\n",
        "            evi_arr[evi_arr == src.nodata] = np.nan\n",
        "        EVI_list.append(evi_arr)\n",
        "\n",
        "    # --- Read cloud mask ---\n",
        "    with rasterio.open(cloud_p) as src:\n",
        "        cloud_arr = src.read(1).astype(\"float32\")\n",
        "        # Cloud masks are typically 0/1; convert nodata to NaN if present\n",
        "        if src.nodata is not None:\n",
        "            cloud_arr[cloud_arr == src.nodata] = np.nan\n",
        "        CLOUD_list.append(cloud_arr)\n",
        "\n",
        "EVI_stack = np.stack(EVI_list, axis=0)      # (time, y, x)\n",
        "CLOUD_stack = np.stack(CLOUD_list, axis=0)  # (time, y, x)\n",
        "\n",
        "print(\"\\Dimensions of the data:\")\n",
        "print(\" EVI_stack shape   (time, y, x):\", EVI_stack.shape)\n",
        "print(\" CLOUD_stack shape (time, y, x):\", CLOUD_stack.shape)\n"
      ],
      "metadata": {
        "id": "wryFbdP0tzt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After all that data pre-processing we're now in a position to do some more interesting stuff with it.\n",
        "\n",
        "As usual, we'll first have a little look at the data by plotting it out, looking at the EVI and cloud mask data side-by-side. The cloud mask data is very simple. Where there is a 1, it means there was a cloud, where there is a 0, there are no clouds.\n",
        "\n",
        "So rather than refer to the layer in the raster stack we want to look at (we'd have to update this in a couple of places), we can set up a variable, _t_  with the layer number that we want to look at.\n",
        "\n",
        "Have a go at viewing several layers representing the EVI and cloud cover at different dates (by changing the value of _t_). Pay attention to what happens to the calculated EVI values where there are clouds."
      ],
      "metadata": {
        "id": "cbetf8-G6vpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot the first layer of the EVI and cloudmask stacks, side by side\n",
        "\n",
        "t = 0  # the layer you want to look at - you can change this! Remember that python indexing starts at 0, so timestep 1 is index 0.\n",
        "dates_dt = [pd.to_datetime(d, format=\"%Y%m%d\") for d in dates] # convert dates to a proper date format for plotting\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# --- EVI ---\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(EVI_stack[t], extent=extent, origin=\"upper\")\n",
        "plt.colorbar(label=\"EVI\")\n",
        "plt.title(f\"EVI (layer {t}, {dates_dt[t].date()})\")             # This is set up so that the plot title will automatically take the date of that layer.\n",
        "plt.xlabel(\"Easting\")\n",
        "plt.ylabel(\"Northing\")\n",
        "plt.locator_params(axis=\"x\", nbins=4)                           # This plots out fewer x-axis tick labels\n",
        "\n",
        "# --- Cloud mask ---\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(CLOUD_stack[t], extent=extent, origin=\"upper\")\n",
        "plt.colorbar(label=\"Cloud mask (1 = cloud/shadow/snow)\")\n",
        "plt.title(f\"Cloud mask (layer {t}, {dates_dt[t].date()})\")      # This is set up so that the plot title will automatically take the date of that layer.\n",
        "plt.xlabel(\"Easting\")\n",
        "plt.ylabel(\"Northing\")\n",
        "plt.locator_params(axis=\"x\", nbins=4)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fQdKvrKVdvEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question: What happens to the EVI values in regions where there are clouds?"
      ],
      "metadata": {
        "id": "buU3egxn93jH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, before doing any further quantitative analysis on the EVI values, let's crop it to the catchment outline as you did last week (the code below is taken from the worksheet last week, and modified for this application).\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "oLhY4PTwn0xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title First, read in data that's provided for you on Github\n",
        "url = \"https://github.com/laura-turnbull-lloyd/IGR_remote_sensing/raw/refs/heads/main/Data/nrfa_25011.zip\"\n",
        "\n",
        "# Download the zip file into memory\n",
        "r = requests.get(url)                         # This downloads whatever is at that URL, in this case a zipped folder containing the catchment data.\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))    # This processes the data so that Python can treat it like an in-memory file.\n",
        "\n",
        "# read in the shapefile\n",
        "z.extractall(\"nrfa_25011\")                    # This extracts all files from the ZIP into a folder called nrfa_25011 in your current working directory.\n",
        "LB_25011 = gpd.read_file(\"nrfa_25011\")        # This reads in the catchment outline data using the geopandas package.\n",
        "catchment = LB_25011.to_crs(landsat_crs)      # This puts the catchment outline in the same coordinate system as the Landsat data."
      ],
      "metadata": {
        "id": "w1BwAe9spGgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Now we can crop the data\n",
        "geoms = [geom.__geo_interface__ for geom in catchment.geometry]\n",
        "\n",
        "xmin, ymin, xmax, ymax = catchment.total_bounds\n",
        "\n",
        "# Build a window and SNAP it to the pixel grid\n",
        "win = from_bounds(xmin, ymin, xmax, ymax, transform=transform)\n",
        "win = win.round_offsets().round_lengths()\n",
        "\n",
        "# Crop stacks using the window (no int slicing)\n",
        "EVI_crop   = EVI_stack[:, win.row_off:win.row_off+win.height,\n",
        "                          win.col_off:win.col_off+win.width]\n",
        "CLOUD_crop = CLOUD_stack[:, win.row_off:win.row_off+win.height,\n",
        "                            win.col_off:win.col_off+win.width]\n",
        "\n",
        "# Updated transform for the cropped arrays\n",
        "transform_crop = rasterio.windows.transform(win, transform)\n",
        "\n",
        "# Mask on the cropped grid\n",
        "inside = geometry_mask(\n",
        "    geoms,\n",
        "    out_shape=(win.height, win.width),\n",
        "    transform=transform_crop,\n",
        "    invert=True  # True = inside geometry is True\n",
        ")\n",
        "\n",
        "EVI_masked = EVI_crop.astype(\"float32\", copy=True)\n",
        "CLOUD_masked = CLOUD_crop.astype(\"float32\", copy=True)\n",
        "\n",
        "EVI_masked[:, ~inside] = np.nan\n",
        "CLOUD_masked[:, ~inside] = np.nan\n",
        "\n",
        "b_crop = window_bounds(win, transform)  # (left, bottom, right, top)\n",
        "left, bottom, right, top = b_crop\n"
      ],
      "metadata": {
        "id": "GhSzABQYVrxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's plot out the EVI cropped data to make sure it all looks good..."
      ],
      "metadata": {
        "id": "vr6VZNSVIO1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "ax.imshow(EVI_masked[1],  origin=\"upper\", extent=[left, right, bottom, top])\n",
        "ax.set_xlabel(\"Easting\")\n",
        "ax.set_ylabel(\"Northing\")\n",
        "ax.set_aspect(\"equal\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nFgmVsBDpZBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Landsat Vegetation Phenology\n",
        "We can now investigate changes in vegetation phenology using the Landsat 9-derived EVI, looking at how it varies over time (see figure below).\n",
        "\n",
        "The EVI is a widely used indicator of vegetation greenness and condition that is designed to be less sensitive to atmospheric effects and background soil influences than simpler vegetation indices such as the NDVI.\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://raw.githubusercontent.com/laura-turnbull-lloyd/IGR_remote_sensing/main/Figures/Seasonal-dynamics-of-the-Enhanced-Vegetation-Index-EVI.png\"\n",
        "       width=\"75%\"\n",
        "       alt=\"Seasonal dynamics of the EVI\">\n",
        "</div>\n",
        "\n",
        "Because the EVI data are stored in a raster stack, we can easily calculate simple summary statistics, such as the mean and median (more robust to outliers) to explore how the EVI changes over time."
      ],
      "metadata": {
        "id": "tjn8TWtVsCnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have a go at exploring vegetation condition over the Langdon Beck catchment over 2025.\n",
        "\n",
        "As well as plotting out the data, we'll also export (to your google drive) the summary dataframe, containing the mean and median values for each date."
      ],
      "metadata": {
        "id": "SHRYFcRbFxHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Summarise the mean and median EVI over time\n",
        "\n",
        "# Median\n",
        "evi_median = np.nanmedian(EVI_masked, axis=(1, 2))  # Here we're calculating the median across all pixels in the catchment (ignores NaNs)\n",
        "                                                    # axis=(1, 2) tells np.nanmedian to take the median across the y and x dimensions\n",
        "                                                    # (rows and columns) for each time step.\n",
        "                                                    # If we were calculating the mean of a single image (without the temporal dimension)\n",
        "                                                    # it would simply be np.nanmedian(EVI_masked)\n",
        "# Mean\n",
        "evi_mean = np.nanmean(EVI_masked, axis=(1, 2))      # And here we're doing the same, but this time calculating the mean\n",
        "\n",
        "# Standard deviation\n",
        "evi_std  = np.nanstd(EVI_masked, axis=(1, 2))\n",
        "\n",
        "# Make sure dates is a pandas-friendly datetime index\n",
        "t = pd.to_datetime(dates)\n",
        "\n",
        "# Put into a table (a better structure for plotting out the time series)\n",
        "summary = pd.DataFrame({\n",
        "    \"date\": t,\n",
        "    \"median_evi\": evi_median,\n",
        "    \"mean_evi\": evi_mean\n",
        "}).sort_values(\"date\").reset_index(drop=True)\n",
        "\n",
        "print(summary)\n",
        "print(\"\\nRows:\", len(summary))\n"
      ],
      "metadata": {
        "id": "uJmlDZXqrnbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Plot date against mean and median EVI\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7,4))\n",
        "ax.plot(summary[\"date\"], summary[\"mean_evi\"], marker=\"o\", color=\"red\",  label=\"Mean EVI\")\n",
        "ax.plot(summary[\"date\"], summary[\"median_evi\"], marker=\"o\", color=\"blue\", label=\"Median EVI\")\n",
        "ax.set_xlabel(\"Date\")\n",
        "ax.set_ylabel(\"EVI\")\n",
        "ax.set_title(\"Catchment mean & median EVI through time\")\n",
        "ax.legend()\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "V1FffLT4LCVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save the summary EVI values to CSV file (i.e. spreadsheet format)\n",
        "out_csv = \"/content/Landsat_evi_time_summary.csv\"\n",
        "summary.to_csv(out_csv, index=False)\n",
        "print(\"\\nSaved:\", out_csv)"
      ],
      "metadata": {
        "id": "C7Z0PvueLINb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question: What was the highest median EVI for Langdon Beck during 2025?"
      ],
      "metadata": {
        "id": "h7KFdniFKdpm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compositing Landsat EVI measurements\n",
        "\n",
        "Due to the fact that we can only do sensible EVI analysis when there's low cloud cover, we don't have any data points extending into the months at the end of the year, and sporadic measurements throughout summer. This is a limitation of EVI measurements using only a single Landsat image.\n",
        "\n",
        "One approach to addressing this limitation in remote sensing is to create was called a composite image, where EVI values calculated for multiple different times are merged together, often taken maximum values, creating what's usually referred to as a maximum value composite. This type of approach allows us to make use of any cloud free pixels across a collection of partially cloudy images.\n",
        "\n",
        "Often, monthly/seasonal maximum value composites are made using Landsat data, so that several images can be merged.\n",
        "\n",
        "Here, we're going to have a go at creating a maximum value composite, for 2025 (seeing as we've already got a collection of files already prepped for 2025!).\n",
        "We will combine all EVI images for the year and, for each pixel, keep the maximum EVI value observed across the time series. This approach is useful because it is likely to capture the years peak vegetation condition (peak greenness/biomass), while reducing the impact of issues like cloud contamination and seasonal snow (we'll come back to this point later).\n",
        "\n",
        "A maximum-value annual composite doesn't tell us anything about within-year vegetation dynamics, but it does provide a robust way to compare year-to-year differences in vegetation condition (should we compare different years).\n"
      ],
      "metadata": {
        "id": "KZJqoYr7R9Wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title EVI maximum value composite calculation\n",
        "EVI_max = np.nanmax(EVI_masked, axis=0)"
      ],
      "metadata": {
        "id": "9mp8r9qAVRbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, on your own, enter code in the code block below to plot out the EVI maximum value composite that you have just created. You may wish to make use of plotting code in this worksheet or the one from last week."
      ],
      "metadata": {
        "id": "qNmgcnzb2bxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Enter your own code to plot out the EVI maximum value composite for 2025\n",
        "\n"
      ],
      "metadata": {
        "id": "hiY1htBo2qZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, see if you can calculate the median value of this maximum value composite, to see how much it varies compared to the highest median value you reported before."
      ],
      "metadata": {
        "id": "yrNECTjWbDsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title On your own, calculate the EVI median of the maximum value composite and print out your result\n",
        "\n",
        "# Enter your code here.\n"
      ],
      "metadata": {
        "id": "lktfTl2AbTec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question: What's the median value of the EVI maximum value composite?"
      ],
      "metadata": {
        "id": "I55Uq3R4bflr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring how vegetation condition/phenology varies between land cover types\n",
        "\n",
        "Last week you explored how the NDVI and EVI varied in relation to the surface cover descriptions that you took in the field.\n",
        "\n",
        "We're going to do a similar task now, but instead of using the surface cover data that represents only a few locations on your hillslope transects, this time we're going to use a land cover dataset (from 2023), which was generated by Centre for Ecology and Hydrology and can be accessed via DigiMap. Information about the dataset can be accessed [here](https://www.ceh.ac.uk/sites/default/files/2024-06/LCM2023ProductDocumentation.pdf). These data have been pre-processes, and clipped to the Langdon Beck catchment.  "
      ],
      "metadata": {
        "id": "QjDzmTaLtVIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Open landcover data\n",
        "url = \"https://github.com/laura-turnbull-lloyd/IGR_remote_sensing/raw/refs/heads/main/Data/landcover_landsat.zip\"\n",
        "\n",
        "# Download the zip file into memory\n",
        "r = requests.get(url)                         # This downloads whatever is at that URL, in this case a zipped folder containing the catchment data.\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))    # This processes the data so that Python can treat it like an in-memory file.\n",
        "\n",
        "# read in the shapefile\n",
        "z.extractall(\"landcover_landsat\")                    # This extracts all files from the ZIP into a folder called Landcover_Langdon in your current working directory.\n",
        "landcover = gpd.read_file(\"landcover_landsat\")    # This reads in the landcover data using the geopandas package.\n",
        "landcover_LB = landcover.to_crs(landsat_crs)"
      ],
      "metadata": {
        "id": "D0xFEna7uaZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the land cover data plots in the correct place..."
      ],
      "metadata": {
        "id": "jWnoCfG9kxau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "ax.imshow(EVI_max,  origin=\"upper\", extent=[left, right, bottom, top])\n",
        "landcover_LB.boundary.plot(ax=ax, linewidth=1, color=\"red\")             # here we're overlaygoverlaying the landcover data as an outline\n",
        "ax.set_title(\"FCC with catchment boundary\")\n",
        "ax.set_xlabel(\"Easting\")\n",
        "ax.set_ylabel(\"Northing\")\n",
        "ax.set_aspect(\"equal\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uI4H6GsdOAZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That looks good, so let's now visualize the land cover classes. These are stored as numeric id's in an attribute called \"_mode\"."
      ],
      "metadata": {
        "id": "s8jKZndOk8Xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "\n",
        "landcover_LB.plot(column=\"_mode\", legend=True, ax=ax)\n",
        "\n",
        "# move legend outside\n",
        "leg = ax.get_legend()\n",
        "leg.set_bbox_to_anchor((1.02, 1))\n",
        "leg.set_loc(\"upper left\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OZr9-zcPlyB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you're familiar with the catchment, hopefully you have some idea which land cover types related to these numeric id's.\n",
        "\n",
        "We can also map these numeric id's onto the the actual land cover description, which will make it a more useful map of land cover."
      ],
      "metadata": {
        "id": "DJzvt2srmH7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These numeric id's correspond to land cover as follows:\n",
        "\n",
        "* 11 = Bog\n",
        "* 4 = Improved grassland\n",
        "* 7 = Acid grassland\n",
        "* 12 = Inland rock\n",
        "* 1 = Deciduous woodland\n",
        "* 21 = Suburban\n",
        "* 2 = Coniferous woodland\n",
        "* 9 = Heather\n",
        "\n",
        "So, we can alter the above code to give the actual land cover descriptions in the legend, to make the map more meaningful:"
      ],
      "metadata": {
        "id": "5ws1m_HjjJAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot out the landcover map again, this time with a more meaningful legend\n",
        "lc_labels = {\n",
        "    \"11\": \"Bog\",\n",
        "    \"4\": \"Improved grassland\",\n",
        "    \"7\": \"Acid grassland\",\n",
        "    \"12\": \"Inland rock\",\n",
        "    \"1\": \"Deciduous woodland\",\n",
        "    \"21\": \"Suburban\",\n",
        "    \"2\": \"Coniferous woodland\",\n",
        "    \"9\": \"Heather\"\n",
        "}\n",
        "\n",
        "landcover_LB[\"lc_name\"] = landcover_LB[\"_mode\"].astype(str).map(lc_labels)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "\n",
        "landcover_LB.plot(column=\"lc_name\", cmap=\"tab10\", legend=True, ax=ax)\n",
        "\n",
        "# move legend outside\n",
        "leg = ax.get_legend()\n",
        "leg.set_bbox_to_anchor((1.02, 1))\n",
        "leg.set_loc(\"upper left\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VxBjKiN9Sbh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question: Does the \"inland rock\" tend to have a higher or lower EVI value?"
      ],
      "metadata": {
        "id": "e0jMNOnHyVEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cV7uEUSfzz0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zonal analysis\n",
        "Now, we're going to do something called \"zonal analysis\", to summarize the mean EVI value for each land cover type at each point in time. This is potentially very valuable as it might enable us to make statements in relation to carbon storage, or how wet the landscape is (remember the tight correlation between the EVI and the normalized difference moisture index last week).\n",
        "\n",
        "This code is quite complicated, but basically what it's doing is cropping the EVI data to each surface cover type, and then it calculates the mean EVI value in that surface cover type.\n",
        "\n",
        "It repeats this for every surface cover type."
      ],
      "metadata": {
        "id": "0Zsvz8tKy03Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "T, H, W = EVI_masked.shape\n",
        "t = pd.to_datetime(dates)\n",
        "rows = []\n",
        "\n",
        "for idx, row in landcover_LB.iterrows():     # This is looping through each surface cover type\n",
        "    geom = row.geometry.__geo_interface__\n",
        "    cls = row[\"_mode\"]\n",
        "\n",
        "    m = geometry_mask([geom], out_shape=(H, W), transform=transform_crop,\n",
        "                      invert=True, all_touched=True)\n",
        "\n",
        "    mean_ts = np.nanmean(EVI_masked[:, m], axis=1)          # This calcualtes the mean EVI\n",
        "\n",
        "    for date, val in zip(t, mean_ts):                          # This summarizes the calculations for each date.\n",
        "        rows.append({\"poly_id\": idx, \"landcover\": cls, \"date\": date, \"mean_evi\": val})\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "# Summarise across polygons for each class and date\n",
        "summary_evi = df.groupby([\"landcover\", \"date\"])[\"mean_evi\"].mean().reset_index()\n"
      ],
      "metadata": {
        "id": "Z9fScGf6KjLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Let's see what the structure of the data looks like\n",
        "print(summary_evi)"
      ],
      "metadata": {
        "id": "V_lSNI0Tfd9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now have a look to see if there's much of a difference in vegetation condition across the different land cover types."
      ],
      "metadata": {
        "id": "EPJhXTwjhrIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot out the time series of EVI for each land cover type\n",
        "\n",
        "lc_labels = {\n",
        "    \"11\": \"Bog\",\n",
        "    \"4\": \"Improved grassland\",\n",
        "    \"7\": \"Acid grassland\",\n",
        "    \"12\": \"Inland rock\",\n",
        "    \"1\": \"Deciduous woodland\",\n",
        "    \"21\": \"Suburban\",\n",
        "    \"2\": \"Coniferous woodland\",\n",
        "    \"9\": \"Heather\"\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "for lc in summary_evi[\"landcover\"].unique():\n",
        "    sub = summary_evi[summary_evi[\"landcover\"] == lc]\n",
        "    label = lc_labels.get(str(lc), str(lc))\n",
        "    plt.plot(sub[\"date\"], sub[\"mean_evi\"], label=label)\n",
        "\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Mean EVI\")\n",
        "plt.title(\"EVI time series by landcover\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fhNn40kSdMMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question: Which land cover type has the most variable EVI throughout the year?"
      ],
      "metadata": {
        "id": "S2EeK4LPnKv2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Longer-term variations in EVI using A MODIS EVI product\n",
        "\n",
        "So far we've worked exlusivley with 30-m resolution Landsat data, which has a revisit period of 16 days.\n",
        "\n",
        "The MODIS satellite, which has a daily revisit period collects surface reflecatance measurements that are suitable for calculating vegetation indices.\n",
        "\n",
        "[MODIS vegetation indices](https://modis.gsfc.nasa.gov/data/dataprod/mod13.php), produced every 16-day and at multiple spatial resolutions (250 m is the finest resolution), provide consistent spatial and temporal comparisons of vegetation canopy greenness, and canopy structure.\n",
        "\n",
        "The 16-day [MODIS EVI product](https://www.earthdata.nasa.gov/data/catalog/lpcloud-mod13q1-061) is a composite image, generated using two 8-day composite surface reflectance data (MOD09A1) in the 16-day period. The MODIS EVI product is computed from atmospherically corrected bi-directional surface reflectances that have been masked for water, clouds, heavy aerosols, and cloud shadows.\n",
        "\n",
        "Here, will explore longer-term variations in vegetation condition using the MODIS EVI data product, which minimizes canopy-soil variations and improves sensitivity over dense vegetation conditions.\n",
        "\n",
        "As usual, we need to first download the data and undertake some basic data processing to get it into a format that we can work with.\n",
        "\n",
        "Note that these data are in the British National Grid projected coordinate system."
      ],
      "metadata": {
        "id": "aWlRWxLctFhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download MODIS EVI data from Github\n",
        "\n",
        "\n",
        "URL = \"https://github.com/laura-turnbull-lloyd/IGR_remote_sensing/raw/refs/heads/main/Data/MODIS_EVI_Langdon_Beck.tif\"\n",
        "DOWNLOAD_DIR = \"/content/downloads\"\n",
        "OUT_PATH = os.path.join(DOWNLOAD_DIR, \"MODIS_EVI_Langdon_Beck.tif\")\n",
        "\n",
        "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
        "\n",
        "def download(url, out_path):\n",
        "    r = requests.get(url, stream=True, allow_redirects=True)\n",
        "    r.raise_for_status()\n",
        "\n",
        "    total = int(r.headers.get(\"content-length\", 0)) or None\n",
        "    chunk = 1024 * 1024\n",
        "\n",
        "    with open(out_path, \"wb\") as f, tqdm(total=total, unit=\"B\", unit_scale=True, desc=os.path.basename(out_path)) as pbar:\n",
        "        for part in r.iter_content(chunk_size=chunk):\n",
        "            if part:\n",
        "                f.write(part)\n",
        "                pbar.update(len(part))\n",
        "\n",
        "download(URL, OUT_PATH)\n",
        "\n",
        "print(\"\\nSaved to:\", OUT_PATH)\n",
        "print(\"Folder contents:\", os.listdir(DOWNLOAD_DIR)[:20])\n",
        "\n",
        "# Check file size\n",
        "size_mb = os.path.getsize(OUT_PATH) / (1024**2)\n",
        "print(f\"File size: {size_mb:.2f} MB\")\n",
        "\n"
      ],
      "metadata": {
        "id": "4E9yZB2Nge-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Open the multi-band GeoTIFF with rasterio\n",
        "\n",
        "TIF_PATH = \"/content/downloads/MODIS_EVI_Langdon_Beck.tif\"\n",
        "\n",
        "with rasterio.open(TIF_PATH) as src:\n",
        "    crs = src.crs                   # Projection\n",
        "    transform = src.transform       # Affine transform\n",
        "    bounds = src.bounds             # Spatial extent\n",
        "    # Band names/descriptions\n",
        "    band_names = list(src.descriptions)  # may contain None entries\n",
        "    band_names = [name[6:] for name in band_names] # tidy up the band names\n",
        "\n",
        "    # Read all bands into memory (bands, rows, cols)\n",
        "    MODIS_EVI = src.read().astype(\"float32\")\n",
        "\n",
        "# Convert nodata to NaN for nicer plotting/stats\n",
        "if src.nodata is not None:\n",
        "    MODIS_EVI[MODIS_EVI == src.nodata] = np.nan\n",
        "\n",
        "print(\"First 10 band names:\", band_names[:10])\n",
        "\n"
      ],
      "metadata": {
        "id": "YG87mxv9v5im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Quick check that the data look okay\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.imshow(MODIS_EVI[0],extent=[bounds.left, bounds.right, bounds.bottom, bounds.top])\n",
        "plt.xlabel(\"Easting\")\n",
        "plt.ylabel(\"Northing\")\n",
        "plt.colorbar(label=\"Value\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-rxrZ-7wFYDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title In the code block below, enter the appropriate code to determine how many time slices of data are there in the MODIS_EVI dataset.\n",
        "\n",
        "# enter your code here\n"
      ],
      "metadata": {
        "id": "5Tfz2A_eMtKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Question: How many time slices of data are there in the MODIS_EVI dataset?"
      ],
      "metadata": {
        "id": "i4BVYlF2MXHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at the data. It's a long dataset so it's useful to have a close inspection, but also to look at multiple time slices together. We can do this in multiple ways. In the code below, there are two functions: one to plot a single band of data, and another to plot many bands of data. There is also an option to plot a subset of data, such as every 12 bands (so you can view the same month across the years).\n",
        "\n",
        "First load the functions, and then experiment with plotting different time slices of the data to get a sense of how the EVI varies over time. To do this, you will need to comment/uncomment the relevant lines using the ```#``` symbol."
      ],
      "metadata": {
        "id": "bBoYgFCziayc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Functions to plot a single/multiple band(s) of data.\n",
        "\n",
        "def plot_band(idx, vmin=None, vmax=None):\n",
        "    \"\"\"Plot a single band index (0-based).\"\"\"\n",
        "    arr = MODIS_EVI[idx]\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    im = plt.imshow(arr, origin=\"upper\", vmin=vmin, vmax=vmax)\n",
        "    plt.title(band_names[idx])\n",
        "    plt.colorbar(im, label=\"EVI\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# Function to plot many bands\n",
        "def plot_many(indices, ncols=6, vmin=None, vmax=None, figsize_per_panel=2.6):\n",
        "    \"\"\"Plot multiple bands in a grid.\"\"\"\n",
        "    n = len(indices)\n",
        "    nrows = math.ceil(n / ncols)\n",
        "    fig, axes = plt.subplots(nrows, ncols, figsize=(figsize_per_panel*ncols, figsize_per_panel*nrows))\n",
        "    axes = np.array(axes).reshape(-1)\n",
        "\n",
        "# specify the min and max values to be displayed\n",
        "    vmin = 0\n",
        "    vmax = 1\n",
        "\n",
        "    for k, i in enumerate(indices):\n",
        "        ax = axes[k]\n",
        "        im = ax.imshow(MODIS_EVI[i], origin=\"upper\", vmin=vmin, vmax=vmax)\n",
        "        ax.set_title(band_names[i], fontsize=8)\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    for j in range(n, len(axes)):\n",
        "        axes[j].axis(\"off\")\n",
        "\n",
        "    fig.colorbar(im, ax=axes[:n], shrink=0.75, label=\"EVI\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "kzEAUaA5jags"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plotting the MODIS EVI\n",
        "\n",
        "# 1) Plot the first band\n",
        "#plot_band(0)    #***uncomment this line if you want to plot a single band\n",
        "\n",
        "# 2) Plot the first x bands as a multipanel (adjust as you like)\n",
        "# plot_many(list(range(min(12, MODIS_EVI.shape[0]))), ncols=6) #***uncomment this line if you want to plot multiple bands.\n",
        "                                                               #***you can change the number 12 - this is how many bands you\n",
        "                                                               #***will plot.\n",
        "\n",
        "# 3) Plot every 10th band (nice for long time series)\n",
        "step = 10  # you can change this\n",
        "idx = list(range(0, MODIS_EVI.shape[0], step))\n",
        "plot_many(idx[:36], ncols=6)  # show up to first 36 panels - you can change this."
      ],
      "metadata": {
        "id": "mVC3-hG6L0lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we'll repeat what we did before, summarizing the EVI values at each timestep by calculating the mean and median values."
      ],
      "metadata": {
        "id": "NEg6z6lalGSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Calculate summary statistics for the MODIS EVI values\n",
        "\n",
        "# Convert the band names into a proper date format\n",
        "dates = [pd.to_datetime(nm[-8:], format=\"%Y%m%d\", errors=\"coerce\") for nm in band_names]\n",
        "\n",
        "# Compute stats for each layer (ignoring NaNs)\n",
        "mean_evi_MODIS   = np.nanmean(MODIS_EVI, axis=(1, 2))\n",
        "median_evi_MODIS = np.nanmedian(MODIS_EVI, axis=(1, 2))\n",
        "\n",
        "# Build a summary table\n",
        "summary_MODIS = pd.DataFrame({\n",
        "    \"band\": np.arange(1, MODIS_EVI.shape[0] + 1),\n",
        "    \"layer_name\": band_names,\n",
        "    \"date\": dates,\n",
        "    \"mean_evi\": mean_evi_MODIS.astype(float),\n",
        "    \"median_evi\": median_evi_MODIS.astype(float),\n",
        "})\n",
        "\n",
        "# df (or df_plot) is your summary table for later use\n",
        "summary_MODIS.head()\n"
      ],
      "metadata": {
        "id": "37tafccfOKfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title On your own, have a go at saving this dataframe to a csv file (you might want to use it in future!)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C4nm8AiUmzsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now for the fun bit. Let's plot out how the mean and median EVI vary through time, from 2020 to 2025."
      ],
      "metadata": {
        "id": "MB1_97_GnlxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the mean and median MODIS EVI on the same figure\n",
        "fig, ax = plt.subplots(figsize=(11, 4))\n",
        "\n",
        "ax.plot(summary_MODIS[\"date\"], summary_MODIS[\"mean_evi\"], marker=\"o\", linewidth=1, label=\"Mean MODIS EVI\", color=\"red\")\n",
        "ax.plot(summary_MODIS[\"date\"], summary_MODIS[\"median_evi\"], marker=\"o\", linewidth=1, label=\"Median MODIS EVI\", color=\"blue\")\n",
        "\n",
        "ax.set_xlabel(\"Date\")\n",
        "ax.set_ylabel(\"EVI\")\n",
        "ax.set_title(\"EVI over Langdon Beck catchment (mean and median)\")\n",
        "ax.grid(True)\n",
        "ax.legend()\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "NPJ6jBTMmVTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you've managed to show the Landsat EVI values alongside the MODIS EVI values, you can append the following to your code in order to zoom in on 2025:\n",
        "\n",
        "```ax.set_xlim(pd.Timestamp(\"2025-01-01\"), pd.Timestamp(\"2025-12-31\"))```\n",
        "\n",
        "This needs to come before\n",
        "```fig.tight_layout()``` and ```plt.show()```\n"
      ],
      "metadata": {
        "id": "Mj-UfbLtpMmh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time to reflect\n",
        "\n",
        "Clearly there is a trade-off between the high-resolution and less frequent Landsat data and the lower resolution, high frequency MODIS data.\n",
        "\n",
        "If your research goal is to be able to make statements about how vegetation condition (or some other surface characteristic) varies over time, in accordance with land use, or something else such as soil type, aspect, or slope, then you might want to consider the scale at which these properties vary. Can the variability in the structure of the landscape be adequately represented by the resolution of the satellite imagery? Here, whether or not it's adequate will depend on your research question.\n",
        "\n",
        "A 250 x 250 m MODIS cell is actually quite large, so in a heterogeneous landscape, the surface reflectance value for a single pixel is going to be an aggregation of smaller scale variability.\n",
        "\n",
        "Despite these limitations, the high acquisition frequency is advantageous, as it reduces the influence of cloud-related data gaps.\n",
        "\n",
        "What is impressive is the high level of agreement between the EVI values measured by the two different sensors. The band widths are actually slightly different (i.e. they're recording slightly different things), but the overall impacts on the resulting EVI is clearly very small.\n",
        "\n"
      ],
      "metadata": {
        "id": "SkU27aU9ohog"
      }
    }
  ]
}